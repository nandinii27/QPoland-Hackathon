{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee6eccc2",
   "metadata": {},
   "source": [
    "## INSTALL NECESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85550d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pennylane pennylane-qiskit \n",
    "# pip install networkx gudhi \n",
    "# pip install scikit-learn numpy scipy -q\n",
    "# pip install quri_parts\n",
    "# pip install torch torch-geometric \n",
    "# pip install pylatexenc\n",
    "# pip install ripser persim \n",
    "# pip install seaborn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03b8ac3",
   "metadata": {},
   "source": [
    "# IMPORT THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88dca6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.utils import to_networkx\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info import Statevector\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.patches import Circle, FancyArrowPatch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e46e6bc",
   "metadata": {},
   "source": [
    "# LOAD THE DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ec5c0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets\n",
      "Loading MUTAG  (188 graphs, 2 classes)\n",
      "Loading AIDS  (2000 graphs, 2 classes)\n",
      "Loading PROTEINS  (1113 graphs, 2 classes)\n",
      "Loading NCI1  (4110 graphs, 2 classes)\n",
      "Loading PTC_MR  (344 graphs, 2 classes)\n",
      "\n",
      "Dataset Statistics:\n",
      "----------------------------------------------------------------------\n",
      "MUTAG        | Graphs:  188 | Classes:  2 | Avg Nodes:  17.9 | Avg Edges:  19.8\n",
      "AIDS         | Graphs: 2000 | Classes:  2 | Avg Nodes:  15.7 | Avg Edges:  16.2\n",
      "PROTEINS     | Graphs: 1113 | Classes:  2 | Avg Nodes:  39.1 | Avg Edges:  72.8\n",
      "NCI1         | Graphs: 4110 | Classes:  2 | Avg Nodes:  29.9 | Avg Edges:  32.3\n",
      "PTC_MR       | Graphs:  344 | Classes:  2 | Avg Nodes:  14.3 | Avg Edges:  14.7\n",
      "----------------------------------------------------------------------\n",
      "\n",
      " All datasets loaded!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading datasets\")\n",
    "\n",
    "# Load all 5 datasets\n",
    "datasets = {}\n",
    "dataset_names = ['MUTAG', 'AIDS', 'PROTEINS', 'NCI1', 'PTC_MR']\n",
    "\n",
    "for name in dataset_names:\n",
    "    print(f\"Loading {name}\", end=\" \")\n",
    "    dataset = TUDataset(root='/tmp/TUDataset', name=name)\n",
    "    \n",
    "    # Convert to NetworkX graphs with labels\n",
    "    graphs = []\n",
    "    labels = []\n",
    "    for data in dataset:\n",
    "        G = to_networkx(data, to_undirected=True)\n",
    "        # Add node attributes if they exist\n",
    "        if data.x is not None:\n",
    "            node_attrs = {i: {'attr': data.x[i].numpy()} for i in range(data.num_nodes)}\n",
    "            nx.set_node_attributes(G, node_attrs)\n",
    "        graphs.append(G)\n",
    "        labels.append(data.y.item())\n",
    "    \n",
    "    datasets[name] = {\n",
    "        'graphs': graphs,\n",
    "        'labels': np.array(labels),\n",
    "        'num_classes': len(np.unique(labels)),\n",
    "        'num_graphs': len(graphs),\n",
    "        'avg_nodes': np.mean([g.number_of_nodes() for g in graphs]),\n",
    "        'avg_edges': np.mean([g.number_of_edges() for g in graphs])\n",
    "    }\n",
    "    print(f\" ({len(graphs)} graphs, {datasets[name]['num_classes']} classes)\")\n",
    "\n",
    "print(\"\\nDataset Statistics:\")\n",
    "print(\"-\" * 70)\n",
    "for name in dataset_names:\n",
    "    d = datasets[name]\n",
    "    print(f\"{name:12s} | Graphs: {d['num_graphs']:4d} | Classes: {d['num_classes']:2d} | \"\n",
    "          f\"Avg Nodes: {d['avg_nodes']:5.1f} | Avg Edges: {d['avg_edges']:5.1f}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\n All datasets loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f871940",
   "metadata": {},
   "source": [
    "# FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af1185b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FEATURE IMPORTANCE ANALYSIS: MUTAG\n",
      "======================================================================\n",
      "Extracting features from all graphs...\n",
      "  Processed 100/188 graphs...\n",
      "✓ Extracted 56 features from 188 graphs\n",
      "Training Random Forest for feature importance...\n",
      "\n",
      "Top 20 Most Important Features:\n",
      "----------------------------------------------------------------------\n",
      "avg_degree                     | chemical     | 0.1001\n",
      "num_edges                      | structural   | 0.0951\n",
      "degree_3_count                 | chemical     | 0.0781\n",
      "max_betweenness                | structural   | 0.0700\n",
      "wiener_index                   | structural   | 0.0694\n",
      "max_closeness                  | structural   | 0.0631\n",
      "avg_closeness                  | structural   | 0.0609\n",
      "num_cycles                     | topological  | 0.0573\n",
      "atom_diversity                 | chemical     | 0.0471\n",
      "num_nodes                      | structural   | 0.0451\n",
      "density                        | structural   | 0.0447\n",
      "avg_eccentricity               | topological  | 0.0417\n",
      "avg_betweenness                | structural   | 0.0385\n",
      "diameter                       | topological  | 0.0350\n",
      "degree_assortativity           | chemical     | 0.0341\n",
      "std_degree                     | chemical     | 0.0270\n",
      "degree_2_count                 | chemical     | 0.0185\n",
      "degree_1_count                 | chemical     | 0.0178\n",
      "avg_cycle_length               | topological  | 0.0130\n",
      "radius                         | topological  | 0.0118\n",
      "\n",
      "Importance by Category:\n",
      "----------------------------------------------------------------------\n",
      "structural      | 0.4868 (48.7%)\n",
      "chemical        | 0.3326 (33.3%)\n",
      "topological     | 0.1805 (18.1%)\n",
      "spectral        | 0.0000 (0.0%)\n",
      "\n",
      "======================================================================\n",
      "FEATURE IMPORTANCE ANALYSIS: AIDS\n",
      "======================================================================\n",
      "Extracting features from all graphs...\n",
      "  Processed 100/2000 graphs...\n",
      "  Processed 200/2000 graphs...\n",
      "  Processed 300/2000 graphs...\n",
      "  Processed 400/2000 graphs...\n",
      "  Processed 500/2000 graphs...\n",
      "  Processed 600/2000 graphs...\n",
      "  Processed 700/2000 graphs...\n",
      "  Processed 800/2000 graphs...\n",
      "  Processed 900/2000 graphs...\n",
      "  Processed 1000/2000 graphs...\n",
      "  Processed 1100/2000 graphs...\n",
      "  Processed 1200/2000 graphs...\n",
      "  Processed 1300/2000 graphs...\n",
      "  Processed 1400/2000 graphs...\n",
      "  Processed 1500/2000 graphs...\n",
      "  Processed 1600/2000 graphs...\n",
      "  Processed 1700/2000 graphs...\n",
      "  Processed 1800/2000 graphs...\n",
      "  Processed 1900/2000 graphs...\n",
      "  Processed 2000/2000 graphs...\n",
      "✓ Extracted 56 features from 2000 graphs\n",
      "Training Random Forest for feature importance...\n",
      "\n",
      "Top 20 Most Important Features:\n",
      "----------------------------------------------------------------------\n",
      "num_nodes                      | structural   | 0.1841\n",
      "num_edges                      | structural   | 0.1495\n",
      "diameter                       | topological  | 0.0967\n",
      "avg_eccentricity               | topological  | 0.0915\n",
      "density                        | structural   | 0.0799\n",
      "radius                         | topological  | 0.0795\n",
      "wiener_index                   | structural   | 0.0535\n",
      "degree_3_count                 | chemical     | 0.0487\n",
      "max_closeness                  | structural   | 0.0424\n",
      "degree_2_count                 | chemical     | 0.0412\n",
      "avg_closeness                  | structural   | 0.0223\n",
      "cycles_len_6                   | topological  | 0.0211\n",
      "degree_1_count                 | chemical     | 0.0148\n",
      "max_cycle_length               | topological  | 0.0117\n",
      "num_cycles                     | topological  | 0.0108\n",
      "atom_diversity                 | chemical     | 0.0096\n",
      "avg_degree                     | chemical     | 0.0092\n",
      "avg_cycle_length               | topological  | 0.0060\n",
      "avg_betweenness                | structural   | 0.0050\n",
      "aromatic_like_rings            | chemical     | 0.0049\n",
      "\n",
      "Importance by Category:\n",
      "----------------------------------------------------------------------\n",
      "structural      | 0.5418 (54.2%)\n",
      "topological     | 0.3196 (32.0%)\n",
      "chemical        | 0.1386 (13.9%)\n",
      "spectral        | 0.0000 (0.0%)\n",
      "\n",
      "======================================================================\n",
      "FEATURE IMPORTANCE ANALYSIS: PROTEINS\n",
      "======================================================================\n",
      "Extracting features from all graphs...\n",
      "  Processed 100/1113 graphs...\n",
      "  Processed 200/1113 graphs...\n",
      "  Processed 300/1113 graphs...\n",
      "  Processed 400/1113 graphs...\n",
      "  Processed 500/1113 graphs...\n",
      "  Processed 600/1113 graphs...\n",
      "  Processed 700/1113 graphs...\n",
      "  Processed 800/1113 graphs...\n",
      "  Processed 900/1113 graphs...\n",
      "  Processed 1000/1113 graphs...\n",
      "  Processed 1100/1113 graphs...\n",
      "✓ Extracted 56 features from 1113 graphs\n",
      "Training Random Forest for feature importance...\n",
      "\n",
      "Top 20 Most Important Features:\n",
      "----------------------------------------------------------------------\n",
      "num_triangles                  | structural   | 0.0672\n",
      "avg_eccentricity               | topological  | 0.0588\n",
      "num_edges                      | structural   | 0.0583\n",
      "cycles_len_3                   | topological  | 0.0488\n",
      "num_cycles                     | topological  | 0.0484\n",
      "avg_closeness                  | structural   | 0.0475\n",
      "three_node_motifs              | structural   | 0.0449\n",
      "degree_assortativity           | chemical     | 0.0415\n",
      "num_nodes                      | structural   | 0.0382\n",
      "avg_clustering                 | structural   | 0.0368\n",
      "max_closeness                  | structural   | 0.0357\n",
      "atom_diversity                 | chemical     | 0.0345\n",
      "diameter                       | topological  | 0.0339\n",
      "avg_degree                     | chemical     | 0.0332\n",
      "degree_4_count                 | chemical     | 0.0321\n",
      "transitivity                   | structural   | 0.0312\n",
      "wiener_index                   | structural   | 0.0309\n",
      "max_betweenness                | structural   | 0.0288\n",
      "avg_betweenness                | structural   | 0.0288\n",
      "std_degree                     | chemical     | 0.0287\n",
      "\n",
      "Importance by Category:\n",
      "----------------------------------------------------------------------\n",
      "structural      | 0.4760 (47.6%)\n",
      "topological     | 0.2745 (27.4%)\n",
      "chemical        | 0.2496 (25.0%)\n",
      "spectral        | 0.0000 (0.0%)\n",
      "\n",
      "======================================================================\n",
      "FEATURE IMPORTANCE ANALYSIS: NCI1\n",
      "======================================================================\n",
      "Extracting features from all graphs...\n",
      "  Processed 100/4110 graphs...\n",
      "  Processed 200/4110 graphs...\n",
      "  Processed 300/4110 graphs...\n",
      "  Processed 400/4110 graphs...\n",
      "  Processed 500/4110 graphs...\n",
      "  Processed 600/4110 graphs...\n",
      "  Processed 700/4110 graphs...\n",
      "  Processed 800/4110 graphs...\n",
      "  Processed 900/4110 graphs...\n",
      "  Processed 1000/4110 graphs...\n",
      "  Processed 1100/4110 graphs...\n",
      "  Processed 1200/4110 graphs...\n",
      "  Processed 1300/4110 graphs...\n",
      "  Processed 1400/4110 graphs...\n",
      "  Processed 1500/4110 graphs...\n",
      "  Processed 1600/4110 graphs...\n",
      "  Processed 1700/4110 graphs...\n",
      "  Processed 1800/4110 graphs...\n",
      "  Processed 1900/4110 graphs...\n",
      "  Processed 2000/4110 graphs...\n",
      "  Processed 2100/4110 graphs...\n",
      "  Processed 2200/4110 graphs...\n",
      "  Processed 2300/4110 graphs...\n",
      "  Processed 2400/4110 graphs...\n",
      "  Processed 2500/4110 graphs...\n",
      "  Processed 2600/4110 graphs...\n",
      "  Processed 2700/4110 graphs...\n",
      "  Processed 2800/4110 graphs...\n",
      "  Processed 2900/4110 graphs...\n",
      "  Processed 3000/4110 graphs...\n",
      "  Processed 3100/4110 graphs...\n",
      "  Processed 3200/4110 graphs...\n",
      "  Processed 3300/4110 graphs...\n",
      "  Processed 3400/4110 graphs...\n",
      "  Processed 3500/4110 graphs...\n",
      "  Processed 3600/4110 graphs...\n",
      "  Processed 3700/4110 graphs...\n",
      "  Processed 3800/4110 graphs...\n",
      "  Processed 3900/4110 graphs...\n",
      "  Processed 4000/4110 graphs...\n",
      "  Processed 4100/4110 graphs...\n",
      "✓ Extracted 56 features from 4110 graphs\n",
      "Training Random Forest for feature importance...\n",
      "\n",
      "Top 20 Most Important Features:\n",
      "----------------------------------------------------------------------\n",
      "max_betweenness                | structural   | 0.0837\n",
      "avg_betweenness                | structural   | 0.0761\n",
      "max_closeness                  | structural   | 0.0516\n",
      "degree_3_count                 | chemical     | 0.0499\n",
      "std_degree                     | chemical     | 0.0494\n",
      "density                        | structural   | 0.0484\n",
      "num_edges                      | structural   | 0.0473\n",
      "degree_assortativity           | chemical     | 0.0461\n",
      "atom_diversity                 | chemical     | 0.0458\n",
      "num_nodes                      | structural   | 0.0426\n",
      "avg_closeness                  | structural   | 0.0414\n",
      "avg_eccentricity               | topological  | 0.0397\n",
      "wiener_index                   | structural   | 0.0375\n",
      "degree_1_count                 | chemical     | 0.0339\n",
      "degree_2_count                 | chemical     | 0.0290\n",
      "num_cycles                     | topological  | 0.0290\n",
      "avg_cycle_length               | topological  | 0.0290\n",
      "avg_degree                     | chemical     | 0.0287\n",
      "cycles_len_6                   | topological  | 0.0270\n",
      "aromatic_like_rings            | chemical     | 0.0202\n",
      "\n",
      "Importance by Category:\n",
      "----------------------------------------------------------------------\n",
      "structural      | 0.4391 (43.9%)\n",
      "chemical        | 0.3294 (32.9%)\n",
      "topological     | 0.2315 (23.1%)\n",
      "spectral        | 0.0000 (0.0%)\n",
      "\n",
      "======================================================================\n",
      "FEATURE IMPORTANCE ANALYSIS: PTC_MR\n",
      "======================================================================\n",
      "Extracting features from all graphs...\n",
      "  Processed 100/344 graphs...\n",
      "  Processed 200/344 graphs...\n",
      "  Processed 300/344 graphs...\n",
      "✓ Extracted 56 features from 344 graphs\n",
      "Training Random Forest for feature importance...\n",
      "\n",
      "Top 20 Most Important Features:\n",
      "----------------------------------------------------------------------\n",
      "atom_diversity                 | chemical     | 0.0761\n",
      "avg_eccentricity               | topological  | 0.0668\n",
      "avg_betweenness                | structural   | 0.0603\n",
      "max_betweenness                | structural   | 0.0598\n",
      "wiener_index                   | structural   | 0.0593\n",
      "std_degree                     | chemical     | 0.0588\n",
      "avg_closeness                  | structural   | 0.0585\n",
      "degree_assortativity           | chemical     | 0.0557\n",
      "max_closeness                  | structural   | 0.0519\n",
      "num_edges                      | structural   | 0.0426\n",
      "density                        | structural   | 0.0406\n",
      "avg_degree                     | chemical     | 0.0395\n",
      "num_nodes                      | structural   | 0.0321\n",
      "attr_std                       | chemical     | 0.0314\n",
      "degree_3_count                 | chemical     | 0.0306\n",
      "degree_2_count                 | chemical     | 0.0302\n",
      "diameter                       | topological  | 0.0293\n",
      "degree_1_count                 | chemical     | 0.0277\n",
      "aromatic_like_rings            | chemical     | 0.0245\n",
      "radius                         | topological  | 0.0186\n",
      "\n",
      "Importance by Category:\n",
      "----------------------------------------------------------------------\n",
      "structural      | 0.4164 (41.6%)\n",
      "chemical        | 0.4086 (40.9%)\n",
      "topological     | 0.1750 (17.5%)\n",
      "spectral        | 0.0000 (0.0%)\n",
      "\n",
      "======================================================================\n",
      "FEATURE MAP DESIGN RECOMMENDATIONS\n",
      "======================================================================\n",
      "\n",
      "MUTAG:\n",
      "  → Primary focus: STRUCTURAL features (48.7%)\n",
      "  → Top 3 features: avg_degree, num_edges, degree_3_count\n",
      "\n",
      "AIDS:\n",
      "  → Primary focus: STRUCTURAL features (54.2%)\n",
      "  → Top 3 features: num_nodes, num_edges, diameter\n",
      "\n",
      "PROTEINS:\n",
      "  → Primary focus: STRUCTURAL features (47.6%)\n",
      "  → Top 3 features: num_triangles, avg_eccentricity, num_edges\n",
      "\n",
      "NCI1:\n",
      "  → Primary focus: STRUCTURAL features (43.9%)\n",
      "  → Top 3 features: max_betweenness, avg_betweenness, max_closeness\n",
      "\n",
      "PTC_MR:\n",
      "  → Primary focus: STRUCTURAL features (41.6%)\n",
      "  → Top 3 features: atom_diversity, avg_eccentricity, avg_betweenness\n"
     ]
    }
   ],
   "source": [
    "def extract_spectral_features(G: nx.Graph) -> dict:\n",
    "    \"\"\"Extract spectral graph theory features.\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Laplacian eigenvalues\n",
    "    try:\n",
    "        L = nx.laplacian_matrix(G).astype(float)\n",
    "        n = G.number_of_nodes()\n",
    "        k = min(10, n-2) if n > 2 else 1\n",
    "        \n",
    "        if k > 0:\n",
    "            eigenvalues = eigsh(L, k=k, which='SM', return_eigenvectors=False)\n",
    "            eigenvalues = np.sort(eigenvalues)\n",
    "            \n",
    "            # Spectral gap (algebraic connectivity)\n",
    "            features['spectral_gap'] = eigenvalues[1] if len(eigenvalues) > 1 else 0\n",
    "            \n",
    "            # Eigenvalue statistics\n",
    "            features['eigen_mean'] = np.mean(eigenvalues)\n",
    "            features['eigen_std'] = np.std(eigenvalues)\n",
    "            features['eigen_max'] = np.max(eigenvalues)\n",
    "            features['eigen_sum'] = np.sum(eigenvalues)\n",
    "            \n",
    "            # Individual eigenvalues (first 5)\n",
    "            for i in range(min(5, len(eigenvalues))):\n",
    "                features[f'eigen_{i}'] = eigenvalues[i]\n",
    "        else:\n",
    "            # Fallback for small graphs\n",
    "            features['spectral_gap'] = 0\n",
    "            features['eigen_mean'] = 0\n",
    "            features['eigen_std'] = 0\n",
    "            features['eigen_max'] = 0\n",
    "            features['eigen_sum'] = 0\n",
    "            for i in range(5):\n",
    "                features[f'eigen_{i}'] = 0\n",
    "                \n",
    "    except Exception as e:\n",
    "        # Fallback values\n",
    "        features['spectral_gap'] = 0\n",
    "        features['eigen_mean'] = 0\n",
    "        features['eigen_std'] = 0\n",
    "        features['eigen_max'] = 0\n",
    "        features['eigen_sum'] = 0\n",
    "        for i in range(5):\n",
    "            features[f'eigen_{i}'] = 0\n",
    "    \n",
    "    # Adjacency eigenvalues (for graph energy)\n",
    "    try:\n",
    "        A = nx.adjacency_matrix(G).astype(float)\n",
    "        if A.shape[0] > 2:\n",
    "            k_adj = min(5, A.shape[0]-2)\n",
    "            adj_eigenvalues = eigsh(A, k=k_adj, which='LM', return_eigenvectors=False)\n",
    "            features['graph_energy'] = np.sum(np.abs(adj_eigenvalues))\n",
    "            features['largest_eigenvalue'] = np.max(np.abs(adj_eigenvalues))\n",
    "        else:\n",
    "            features['graph_energy'] = 0\n",
    "            features['largest_eigenvalue'] = 0\n",
    "    except:\n",
    "        features['graph_energy'] = 0\n",
    "        features['largest_eigenvalue'] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_topological_features(G: nx.Graph) -> dict:\n",
    "    \"\"\"Extract topological features (cycles, connectivity, holes).\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Basic topology\n",
    "    features['num_nodes'] = G.number_of_nodes()\n",
    "    features['num_edges'] = G.number_of_edges()\n",
    "    features['density'] = nx.density(G)\n",
    "    \n",
    "    # Connectivity\n",
    "    features['is_connected'] = int(nx.is_connected(G))\n",
    "    features['num_components'] = nx.number_connected_components(G)\n",
    "    \n",
    "    # Cycles and loops\n",
    "    try:\n",
    "        cycle_basis = nx.cycle_basis(G)\n",
    "        features['num_cycles'] = len(cycle_basis)\n",
    "        features['avg_cycle_length'] = np.mean([len(c) for c in cycle_basis]) if cycle_basis else 0\n",
    "        features['max_cycle_length'] = max([len(c) for c in cycle_basis]) if cycle_basis else 0\n",
    "        \n",
    "        # Cycle length distribution\n",
    "        cycle_lengths = [len(c) for c in cycle_basis]\n",
    "        for k in [3, 4, 5, 6, 7]:  # Common ring sizes in chemistry\n",
    "            features[f'cycles_len_{k}'] = sum(1 for l in cycle_lengths if l == k)\n",
    "    except:\n",
    "        features['num_cycles'] = 0\n",
    "        features['avg_cycle_length'] = 0\n",
    "        features['max_cycle_length'] = 0\n",
    "        for k in [3, 4, 5, 6, 7]:\n",
    "            features[f'cycles_len_{k}'] = 0\n",
    "    \n",
    "    # Euler characteristic (topological invariant)\n",
    "    # χ = V - E + F for planar graphs, approximate with cycles\n",
    "    features['euler_characteristic'] = features['num_nodes'] - features['num_edges'] + features['num_cycles']\n",
    "    \n",
    "    # Diameter and radius\n",
    "    try:\n",
    "        if nx.is_connected(G):\n",
    "            features['diameter'] = nx.diameter(G)\n",
    "            features['radius'] = nx.radius(G)\n",
    "            features['avg_eccentricity'] = np.mean([nx.eccentricity(G, v) for v in G.nodes()])\n",
    "        else:\n",
    "            # Use largest component\n",
    "            largest_cc = max(nx.connected_components(G), key=len)\n",
    "            G_sub = G.subgraph(largest_cc)\n",
    "            features['diameter'] = nx.diameter(G_sub)\n",
    "            features['radius'] = nx.radius(G_sub)\n",
    "            features['avg_eccentricity'] = np.mean([nx.eccentricity(G_sub, v) for v in G_sub.nodes()])\n",
    "    except:\n",
    "        features['diameter'] = 0\n",
    "        features['radius'] = 0\n",
    "        features['avg_eccentricity'] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_chemical_features(G: nx.Graph) -> dict:\n",
    "    \"\"\"Extract chemistry-specific features (assuming molecular graphs).\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Node attributes \n",
    "    if G.number_of_nodes() > 0:\n",
    "        node_attrs = list(G.nodes(data=True))\n",
    "        \n",
    "        # Check if node attributes exist\n",
    "        has_attrs = 'attr' in node_attrs[0][1] if node_attrs else False\n",
    "        \n",
    "        if has_attrs:\n",
    "            # Atom type diversity (using attribute vectors)\n",
    "            attr_vectors = [data['attr'] for _, data in node_attrs]\n",
    "            attr_array = np.array(attr_vectors)\n",
    "            \n",
    "            # Feature statistics\n",
    "            features['attr_mean'] = np.mean(attr_array)\n",
    "            features['attr_std'] = np.std(attr_array)\n",
    "            features['attr_max'] = np.max(attr_array)\n",
    "            features['attr_min'] = np.min(attr_array)\n",
    "            \n",
    "            # Diversity (unique attribute patterns)\n",
    "            unique_attrs = len(set(tuple(row) for row in attr_array))\n",
    "            features['atom_diversity'] = unique_attrs / len(attr_array) if len(attr_array) > 0 else 0\n",
    "        else:\n",
    "            features['attr_mean'] = 0\n",
    "            features['attr_std'] = 0\n",
    "            features['attr_max'] = 0\n",
    "            features['attr_min'] = 0\n",
    "            features['atom_diversity'] = 0\n",
    "    \n",
    "    # Degree distribution (bond counts)\n",
    "    degrees = [d for n, d in G.degree()]\n",
    "    if degrees:\n",
    "        features['avg_degree'] = np.mean(degrees)\n",
    "        features['std_degree'] = np.std(degrees)\n",
    "        features['max_degree'] = np.max(degrees)\n",
    "        features['min_degree'] = np.min(degrees)\n",
    "        \n",
    "        # Degree distribution counts\n",
    "        degree_counts = np.bincount(degrees, minlength=7)\n",
    "        for i in range(1, 7):  # Degrees 1-6\n",
    "            features[f'degree_{i}_count'] = degree_counts[i] if i < len(degree_counts) else 0\n",
    "    else:\n",
    "        features['avg_degree'] = 0\n",
    "        features['std_degree'] = 0\n",
    "        features['max_degree'] = 0\n",
    "        features['min_degree'] = 0\n",
    "        for i in range(1, 7):\n",
    "            features[f'degree_{i}_count'] = 0\n",
    "    \n",
    "    # Aromaticity proxy (6-cycles with specific degree patterns)\n",
    "    try:\n",
    "        six_cycles = [c for c in nx.cycle_basis(G) if len(c) == 6]\n",
    "        aromatic_like = 0\n",
    "        for cycle in six_cycles:\n",
    "            degrees_in_cycle = [G.degree(n) for n in cycle]\n",
    "            # Aromatic rings typically have degree 2 or 3 carbons\n",
    "            if all(2 <= d <= 3 for d in degrees_in_cycle):\n",
    "                aromatic_like += 1\n",
    "        features['aromatic_like_rings'] = aromatic_like\n",
    "    except:\n",
    "        features['aromatic_like_rings'] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_structural_features(G: nx.Graph) -> dict:\n",
    "    \"\"\"Extract structural/motif features (triangles, cliques, paths).\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Clustering and transitivity\n",
    "    features['avg_clustering'] = nx.average_clustering(G)\n",
    "    features['transitivity'] = nx.transitivity(G)\n",
    "    \n",
    "    # Triangle count\n",
    "    triangles = sum(nx.triangles(G).values()) // 3\n",
    "    features['num_triangles'] = triangles\n",
    "    \n",
    "    # Clique number\n",
    "    try:\n",
    "        features['clique_number'] = nx.graph_clique_number(G)\n",
    "    except:\n",
    "        features['clique_number'] = 0\n",
    "    \n",
    "    # Motif counts (small subgraphs)\n",
    "    # Count 3-node motifs\n",
    "    three_node_motifs = 0\n",
    "    for nodes in nx.enumerate_all_cliques(G):\n",
    "        if len(nodes) == 3:\n",
    "            three_node_motifs += 1\n",
    "        elif len(nodes) > 3:\n",
    "            break\n",
    "    features['three_node_motifs'] = three_node_motifs\n",
    "    \n",
    "    # Assortativity (degree correlation)\n",
    "    try:\n",
    "        features['degree_assortativity'] = nx.degree_assortativity_coefficient(G)\n",
    "    except:\n",
    "        features['degree_assortativity'] = 0\n",
    "    \n",
    "    # Wiener index (sum of shortest paths)\n",
    "    try:\n",
    "        if nx.is_connected(G) and G.number_of_nodes() < 100:  # Limit for computational efficiency\n",
    "            features['wiener_index'] = nx.wiener_index(G)\n",
    "        else:\n",
    "            features['wiener_index'] = 0\n",
    "    except:\n",
    "        features['wiener_index'] = 0\n",
    "    \n",
    "    # Centrality statistics\n",
    "    try:\n",
    "        if G.number_of_nodes() < 500:  # Computational limit\n",
    "            betweenness = list(nx.betweenness_centrality(G).values())\n",
    "            features['avg_betweenness'] = np.mean(betweenness)\n",
    "            features['max_betweenness'] = np.max(betweenness)\n",
    "            \n",
    "            closeness = list(nx.closeness_centrality(G).values())\n",
    "            features['avg_closeness'] = np.mean(closeness)\n",
    "            features['max_closeness'] = np.max(closeness)\n",
    "        else:\n",
    "            features['avg_betweenness'] = 0\n",
    "            features['max_betweenness'] = 0\n",
    "            features['avg_closeness'] = 0\n",
    "            features['max_closeness'] = 0\n",
    "    except:\n",
    "        features['avg_betweenness'] = 0\n",
    "        features['max_betweenness'] = 0\n",
    "        features['avg_closeness'] = 0\n",
    "        features['max_closeness'] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_all_features(G: nx.Graph) -> dict:\n",
    "    \"\"\"Extract all feature categories.\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    features.update(extract_spectral_features(G))\n",
    "    features.update(extract_topological_features(G))\n",
    "    features.update(extract_chemical_features(G))\n",
    "    features.update(extract_structural_features(G))\n",
    "    \n",
    "    return features\n",
    "\n",
    "def compute_feature_importance(graphs: list, labels: np.ndarray, \n",
    "                               dataset_name: str = \"Dataset\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute feature importance using Random Forest.\n",
    "    \n",
    "    Args:\n",
    "        graphs: List of NetworkX graphs\n",
    "        labels: Target labels\n",
    "        dataset_name: Name of dataset for display\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with feature importances\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"FEATURE IMPORTANCE ANALYSIS: {dataset_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Extract features for all graphs\n",
    "    print(\"Extracting features from all graphs...\")\n",
    "    feature_list = []\n",
    "    for i, G in enumerate(graphs):\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"  Processed {i+1}/{len(graphs)} graphs...\")\n",
    "        features = extract_all_features(G)\n",
    "        feature_list.append(features)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df_features = pd.DataFrame(feature_list)\n",
    "    \n",
    "    # Handle NaN/Inf values\n",
    "    df_features = df_features.replace([np.inf, -np.inf], np.nan)\n",
    "    df_features = df_features.fillna(0)\n",
    "    \n",
    "    print(f\"✓ Extracted {df_features.shape[1]} features from {df_features.shape[0]} graphs\")\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(df_features)\n",
    "    \n",
    "    # Train Random Forest for feature importance\n",
    "    print(\"Training Random Forest for feature importance...\")\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_scaled, labels)\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = rf.feature_importances_\n",
    "    feature_names = df_features.columns\n",
    "    \n",
    "    # Create importance DataFrame\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances,\n",
    "        'category': [categorize_feature(f) for f in feature_names]\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Print top features\n",
    "    print(f\"\\nTop 20 Most Important Features:\")\n",
    "    print(\"-\" * 70)\n",
    "    for idx, row in importance_df.head(20).iterrows():\n",
    "        print(f\"{row['feature']:30s} | {row['category']:12s} | {row['importance']:.4f}\")\n",
    "    \n",
    "    # Category-wise importance\n",
    "    category_importance = importance_df.groupby('category')['importance'].sum().sort_values(ascending=False)\n",
    "    print(f\"\\nImportance by Category:\")\n",
    "    print(\"-\" * 70)\n",
    "    for category, imp in category_importance.items():\n",
    "        print(f\"{category:15s} | {imp:.4f} ({imp/category_importance.sum()*100:.1f}%)\")\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "\n",
    "def categorize_feature(feature_name: str) -> str:\n",
    "    \"\"\"Categorize feature into spectral, topological, chemical, or structural.\"\"\"\n",
    "    if any(x in feature_name for x in ['eigen', 'spectral', 'energy', 'laplacian']):\n",
    "        return 'spectral'\n",
    "    elif any(x in feature_name for x in ['cycle', 'euler', 'diameter', 'radius', 'component', 'connected', 'eccentricity']):\n",
    "        return 'topological'\n",
    "    elif any(x in feature_name for x in ['attr', 'atom', 'aromatic', 'degree']):\n",
    "        return 'chemical'\n",
    "    else:\n",
    "        return 'structural'\n",
    "\n",
    "def run_feature_importance_analysis(datasets: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Run feature importance analysis on all datasets.\n",
    "    \n",
    "    Args:\n",
    "        datasets: Dictionary from the setup script\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of importance DataFrames\n",
    "    \"\"\"\n",
    "    importance_results = {}\n",
    "    \n",
    "    for dataset_name in ['MUTAG', 'AIDS', 'PROTEINS', 'NCI1', 'PTC_MR']:\n",
    "        graphs = datasets[dataset_name]['graphs']\n",
    "        labels = datasets[dataset_name]['labels']\n",
    "        \n",
    "        importance_df = compute_feature_importance(graphs, labels, dataset_name)\n",
    "        importance_results[dataset_name] = importance_df\n",
    "    \n",
    "    # Summary recommendations\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"FEATURE MAP DESIGN RECOMMENDATIONS\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    for dataset_name, importance_df in importance_results.items():\n",
    "        print(f\"\\n{dataset_name}:\")\n",
    "        category_imp = importance_df.groupby('category')['importance'].sum().sort_values(ascending=False)\n",
    "        top_cat = category_imp.index[0]\n",
    "        print(f\"  → Primary focus: {top_cat.upper()} features ({category_imp[top_cat]/category_imp.sum()*100:.1f}%)\")\n",
    "        print(f\"  → Top 3 features: {', '.join(importance_df.head(3)['feature'].tolist())}\")\n",
    "    \n",
    "    return importance_results\n",
    "\n",
    "importance_results = run_feature_importance_analysis(datasets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
